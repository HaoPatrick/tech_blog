<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"  lang="en-us" >

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" /> 
    <title>Paper Review: Indexing | Xiangpeng Hao</title>
     <meta property='og:title' content='Paper Review: Indexing - Xiangpeng Hao'>
<meta property='og:description' content='Key words: many-core, latch-free, cache, memory
The Bw-Tree: A B-tree for New Hardware Platforms BwTree is a b&#43;tree trying to fit with multi-core processor and flash based storage. To deal with multi-core processors the authors argued we ultimately need to achieve latch-free in order to eliminate the thread synchronization cost. To co-operate with the flash storage, the BwTree utilized the mapping table as the base for other innovations, such as delta updating and less internal node modifications.'>
<meta property='og:url' content='/posts/paper-review-3/'>
<meta property='og:site_name' content='Xiangpeng Hao'>
<meta property='og:type' content='article'><meta property='article:section' content='Posts'><meta property='article:published_time' content='2020-01-27T14:32:18-08:00'/><meta property='article:modified_time' content='2020-01-27T14:32:18-08:00'/><meta name='twitter:card' content='summary'><meta name='twitter:site' content='@'><meta name='twitter:creator' content='@'>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="shortcut icon" href="favicon.png" /></head>

<body>
<section class="section">
  <div class="container">
    <nav class="nav">
      <div class="nav-left">
        <a class="nav-item" href="/"><h1 class="title is-4">Xiangpeng Hao</h1></a>
      </div>
      <div class="nav-right">
        <nav class="nav-item level is-mobile"><a class="level-item" href='https://haoxp.xyz' target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <g transform="scale(0.042)" stroke-width="4">
        <path fill="currentColor"
            d="M528 32H48C21.5 32 0 53.5 0 80v352c0 26.5 21.5 48 48 48h480c26.5 0 48-21.5 48-48V80c0-26.5-21.5-48-48-48zm0 400H48V80h480v352zM208 256c35.3 0 64-28.7 64-64s-28.7-64-64-64-64 28.7-64 64 28.7 64 64 64zm-89.6 128h179.2c12.4 0 22.4-8.6 22.4-19.2v-19.2c0-31.8-30.1-57.6-67.2-57.6-10.8 0-18.7 8-44.8 8-26.9 0-33.4-8-44.8-8-37.1 0-67.2 25.8-67.2 57.6v19.2c0 10.6 10 19.2 22.4 19.2zM360 320h112c4.4 0 8-3.6 8-8v-16c0-4.4-3.6-8-8-8H360c-4.4 0-8 3.6-8 8v16c0 4.4 3.6 8 8 8zm0-64h112c4.4 0 8-3.6 8-8v-16c0-4.4-3.6-8-8-8H360c-4.4 0-8 3.6-8 8v16c0 4.4 3.6 8 8 8zm0-64h112c4.4 0 8-3.6 8-8v-16c0-4.4-3.6-8-8-8H360c-4.4 0-8 3.6-8 8v16c0 4.4 3.6 8 8 8z">
        </path>
        
    </g>
    
</svg></i>
            </span>
          </a><a class="level-item" href='https://github.com/XiangpengHao' target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22" />
    
</svg></i>
            </span>
          </a><a class="level-item" href='https://linkedin.com/in/hao-xiangpeng' target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path stroke-width="1.8"
        d="m5.839218,4.101561c0,1.211972 -0.974141,2.194011 -2.176459,2.194011s-2.176459,-0.982039 -2.176459,-2.194011c0,-1.211094 0.974141,-2.194011 2.176459,-2.194011s2.176459,0.982917 2.176459,2.194011zm0.017552,3.94922l-4.388022,0l0,14.04167l4.388022,0l0,-14.04167zm7.005038,0l-4.359939,0l0,14.04167l4.360816,0l0,-7.370999c0,-4.098413 5.291077,-4.433657 5.291077,0l0,7.370999l4.377491,0l0,-8.89101c0,-6.915523 -7.829986,-6.66365 -9.669445,-3.259423l0,-1.891237z" />
    
</svg></i>
            </span>
          </a><a class="level-item" href='https://blog.haoxp.xyz/index.xml' target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <g transform="scale(0.045)" stroke-width="40">
        <path
            d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z">
        </path>
    </g>
    
    
</svg></i>
            </span>
          </a><a class="level-item" href='https://t.me/newsathlh' target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path
        d="m 22.05,1.577 c -0.393,-0.016 -0.784,0.08 -1.117,0.235 -0.484,0.186 -4.92,1.902 -9.41,3.64 C 9.263,6.325 7.005,7.198 5.267,7.867 3.53,8.537 2.222,9.035 2.153,9.059 c -0.46,0.16 -1.082,0.362 -1.61,0.984 -0.79581202,1.058365 0.21077405,1.964825 1.004,2.499 1.76,0.564 3.58,1.102 5.087,1.608 0.556,1.96 1.09,3.927 1.618,5.89 0.174,0.394 0.553,0.54 0.944,0.544 l -0.002,0.02 c 0,0 0.307,0.03 0.606,-0.042 0.3,-0.07 0.677,-0.244 1.02,-0.565 0.377,-0.354 1.4,-1.36 1.98,-1.928 l 4.37,3.226 0.035,0.02 c 0,0 0.484,0.34 1.192,0.388 0.354,0.024 0.82,-0.044 1.22,-0.337 0.403,-0.294 0.67,-0.767 0.795,-1.307 0.374,-1.63 2.853,-13.427 3.276,-15.38 L 23.676,4.725 C 23.972,3.625 23.863,2.617 23.18,2.02 22.838,1.723 22.444,1.593 22.05,1.576 Z" />
    
</svg></i>
            </span>
          </a></nav>
      </div>
    </nav>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="subtitle is-6 is-pulled-right">
      
    </div>
    <h2 class="subtitle is-6">January 27, 2020</h2>
    <h1 class="title">Paper Review: Indexing</h1>
    
    <div class="content">
      

<p>Key words: many-core, latch-free, cache, memory</p>

<h3 id="the-bw-tree-a-b-tree-for-new-hardware-platforms">The Bw-Tree: A B-tree for New Hardware Platforms</h3>

<p>BwTree is a b+tree trying to fit with multi-core processor and flash based storage.
To deal with multi-core processors the authors argued we ultimately need to achieve latch-free in order to eliminate the thread synchronization cost.
To co-operate with the flash storage, the BwTree utilized the mapping table as the base for other innovations, such as delta updating and less internal node modifications.</p>

<p>Latch-free is one of the most common words in the paper, probably because back to 2013 people tend to agree that lock based synchronization does not scale to many-core cpus.
So the latch-free paradigm becomes the new hot topic.
Yet from the 2020 point of view, there&rsquo;re less paper talking about latch-free algorithms.</p>

<p>There are at least three reasons for that:
1. Latch-free is too complex to get correct. The implementation requires thread help-along, while it&rsquo;s extremely difficult to test every possible cases.
2. The benefits of being latch-free is not large enough to out-perform its complexity cost.
3. Most thread help-along does not produce meaningful work, rather they have side effects: consumes too much memory bandwidth thus leaves less resources to the remaining of the system.</p>

<p>Speaking of index for new hardware, my favorite in-memory index tree is the ART.
Although the ART paper only highlighted the tricks they used to reduce memory consumption, the implication of the overall design is deep and profound.
On the one hand, they achieved almost optimal information gain per cache line visit by storing the keys implicitly along the query path.
This means that each query requires less memory load to traverse the tree and thus saves a lot of bandwidth.
On the other hand, the lazy expansion is actually prefix-compression,
i.e. in most query cases the thread only need to load a portion of the key to reach the leaf node.</p>

<h3 id="palm-parallel-architecture-friendly-latch-free-modifications-to-b-trees-on-many-core-processors">PALM: Parallel Architecture-Friendly Latch-Free Modifications to B+ Trees on Many-Core Processors</h3>

<p>The key idea of this paper is Bulk Synchronous Parallel, which is common in graph processing but less so in database indexes.
The paper used BSP to avoid race conditions and deadlocks, at the cost of tail latencies.
What&rsquo;s more, the thread model has quite deviated from the traditional transaction-based thread model.
In this paper, there&rsquo;s a group of threads dedicated for the index, i.e. these threads all in a thread pool that cannot be reused by other work.
This thread model significantly limited the usage of this index as it&rsquo;s incompatible with the remaining system.
This paper, however, is insightful in terms of exploring the usage of BSP in in-memory indexes.</p>

<p>The paper only evaluated the performance within 12 cores, and I&rsquo;m extremely skeptical to the scalability of the whole system, as there&rsquo;s a global <code>sync</code> after step 1,
which can be a major bottleneck once the core count increase to a practical count.</p>

<p>Also notice that all the evaluations in the paper are with 4-byte keys, which is unrealistic in real world scenarios and gives SIMD acceleration unfair advantages.</p>

<p>What&rsquo;s more, the latency evaluation shows that 99% peak throughput has 350 us latency.
To the best of my knowledge, most in-memory indexes has less than 10 us read latency at 99% throughput.
Yet the authors claimed &ldquo;These response time are low enough to allow our scheme to be used even in real-time databases.&rdquo;</p>

<p>Nevertheless, it&rsquo;s good to know people trying to integrate BSP into range indexes.
(I would hope they perform more comprehensive evaluations though, even if the idea doesn&rsquo;t actually work)</p>

      
    </div>
    
  </div>
</section>


<section class="section">
  <div class="container has-text-centered">
    <p><a href="https://www.haoxp.xyz">Xiangpeng Hao</a> 2020</p>
    
  </div>
</section>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-66103952-7', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</body>
</html>

